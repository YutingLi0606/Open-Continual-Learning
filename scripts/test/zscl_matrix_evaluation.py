import os
import re
import sys
import csv
import json
import subprocess
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional



class ZSCLMatrixEvaluator:
    
    def __init__(self):
        self.datasets = [
            "Aircraft", "Caltech101", "CIFAR100", "DTD", "EuroSAT", 
            "Flowers", "Food", "MNIST", "OxfordPet", "StanfordCars", "SUN397"
        ]
        self.accuracy_matrix = np.zeros((11, 11))
        
    def cal_ZSCL_metrics(self, acc_matrix):
        """
        è®¡ç®—ZSCLæŒ‡æ ‡ï¼ŒåŒ…æ‹¬Transferã€Averageå’ŒLastæ€§èƒ½
        """
        acc_matrix = np.array(acc_matrix)
        acc_matrix *= 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        
        avg = acc_matrix.mean(axis=0)  # æ¯åˆ—çš„å¹³å‡å€¼
        last = np.array(acc_matrix[-1, :])  # æœ€åä¸€è¡Œ
        
        # Transfer: å¯¹æ¯ä¸ªæ•°æ®é›†ï¼Œè®¡ç®—ä¹‹å‰è®­ç»ƒçš„æ‰€æœ‰æ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸Šçš„å¹³å‡æ€§èƒ½
        transfer = np.array([
            np.mean([acc_matrix[j, i] for j in range(i)]) if i > 0 else 0
            for i in range(acc_matrix.shape[1])
        ])
        
        g = lambda x: np.around(x.mean(), decimals=1) if len(x) > 0 else -1
        f = lambda x: [np.around(i, decimals=1) for i in x]
        s = lambda x: np.around(x.sum(), decimals=1) if len(x) > 0 else -1
        return {
            "transfer": {"transfer": f(transfer)}, 
            "avg": {"avg": f(avg)}, 
            "last": {"last": f(last)}, 
            "results_mean": {
                "transfer": s(transfer)/10, # Transferä»ç¬¬2ä¸ªä»»åŠ¡å¼€å§‹è®¡ç®—
                "avg": g(avg), 
                "last": g(last)
            }
        }
    
    def run_test_script_and_capture_matrix(self, test_script_path: str = "scripts/test_zscl.sh") -> np.ndarray:
        """
        è¿è¡ŒZSCLæµ‹è¯•è„šæœ¬å¹¶æ•è·11x11çŸ©é˜µç»“æœ
        """
        if not os.path.exists(test_script_path):
            raise FileNotFoundError(f"æµ‹è¯•è„šæœ¬ä¸å­˜åœ¨: {test_script_path}")
        
        log_file = f"zscl_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        try:
            with open(log_file, 'w') as f:
                process = subprocess.Popen(
                    ['bash', test_script_path], 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.STDOUT, 
                    universal_newlines=True
                )
                
                for line in process.stdout:
                    print(line.strip())  # å®æ—¶æ˜¾ç¤ºè¾“å‡º
                    f.write(line)  # åŒæ—¶å†™å…¥æ—¥å¿—æ–‡ä»¶
                
                process.wait()
            
            # è§£ææ—¥å¿—æ–‡ä»¶ç”ŸæˆçŸ©é˜µ
            matrix = self.parse_log_to_matrix(log_file)
            
            return matrix
            
        except Exception as e:
            print(f"è¿è¡Œæµ‹è¯•è„šæœ¬æ—¶å‡ºé”™: {e}")
            return np.zeros((11, 11))
    
    def parse_log_to_matrix(self, log_file: str) -> np.ndarray:
        """
        è§£æZSCLæµ‹è¯•æ—¥å¿—æ–‡ä»¶ï¼Œæå–11x11å‡†ç¡®ç‡çŸ©é˜µ
        """
        matrix = np.zeros((11, 11))
        with open(log_file, 'r') as f:
            content = f.read()
        
        # è§£æé€»è¾‘ï¼šæŸ¥æ‰¾åŠ è½½checkpointå’Œè¯„ä¼°ç»“æœçš„æ¨¡å¼
        lines = content.split('\n')
        
        current_model_idx = -1
        current_dataset_idx = -1
        
        print("ğŸ” è§£ææ—¥å¿—æ–‡ä»¶...")
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # æ£€æµ‹åŠ è½½çš„æ¨¡å‹checkpoint
            if "Checkpoint loaded from" in line and ".pth" in line:
                # æå–æ¨¡å‹åç§° - ZSCLæ¨¡å‹æŒ‰æ•°æ®é›†åç§°ä¿å­˜
                model_match = re.search(r'/([^/]+)\.pth', line)
                if model_match:
                    model_name = model_match.group(1)
                    if model_name in self.datasets:
                        current_model_idx = self.datasets.index(model_name)
                        print(f"   æ£€æµ‹åˆ°æ¨¡å‹: {model_name} (ç´¢å¼•: {current_model_idx})")
            
            # æ£€æµ‹æ­£åœ¨è¯„ä¼°çš„æ•°æ®é›†
            elif line.startswith("Evaluating on "):
                dataset_match = re.search(r"Evaluating on (\w+)", line)
                if dataset_match:
                    dataset_name = dataset_match.group(1)
                    if dataset_name in self.datasets:
                        current_dataset_idx = self.datasets.index(dataset_name)
                        print(f"   æ£€æµ‹åˆ°æ•°æ®é›†: {dataset_name} (ç´¢å¼•: {current_dataset_idx})")
            
            # æ£€æµ‹å‡†ç¡®ç‡ç»“æœ
            elif line.startswith("Top-1 accuracy:") and current_model_idx >= 0 and current_dataset_idx >= 0:
                acc_match = re.search(r"Top-1 accuracy: ([\d.]+)", line)
                if acc_match:
                    accuracy = float(acc_match.group(1))
                    # å¦‚æœå‡†ç¡®ç‡å·²ç»æ˜¯ç™¾åˆ†æ¯”æ ¼å¼ï¼Œå°±é™¤ä»¥100ï¼›å¦‚æœæ˜¯å°æ•°æ ¼å¼ï¼Œä¿æŒä¸å˜
                    if accuracy > 1.0:
                        accuracy = accuracy / 100.0
                    matrix[current_model_idx, current_dataset_idx] = accuracy
                    print(f"   è®°å½•å‡†ç¡®ç‡: æ¨¡å‹{current_model_idx}->æ•°æ®é›†{current_dataset_idx} = {accuracy:.4f}")
            
            i += 1
        
        print(f"âœ… è§£æå®Œæˆï¼Œéé›¶å…ƒç´ æ•°é‡: {np.count_nonzero(matrix)}")
        return matrix
    
    def save_accuracy_matrix_csv(self, matrix: np.ndarray, output_path: str):
        """
        å°†å‡†ç¡®ç‡çŸ©é˜µä¿å­˜ä¸ºCSVæ–‡ä»¶
        """
        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # å†™å…¥è¡¨å¤´
            header = ["Model\\Dataset"] + self.datasets
            writer.writerow(header)
            
            # å†™å…¥æ¯ä¸€è¡Œæ•°æ®
            for i, model_name in enumerate(self.datasets):
                row = [model_name] + [f"{matrix[i, j]*100:.2f}" for j in range(11)]
                writer.writerow(row)

    
    def save_zscl_metrics_csv(self, metrics: Dict, experiment_name: str, output_path: str):
        """
        å°†ZSCLæŒ‡æ ‡ä¿å­˜ä¸ºCSVæ–‡ä»¶
        """
        # CSVè¡¨å¤´ï¼šç¬¬ä¸€åˆ—ä¸ºæŒ‡æ ‡ç±»å‹ï¼Œç¬¬äºŒåˆ—ä¸ºæ–¹æ³•åï¼Œåé¢æ˜¯å„æ•°æ®é›†ç»“æœï¼Œæœ€åä¸€åˆ—æ˜¯å¹³å‡å€¼
        csv_headers = ["", "Method"] + self.datasets + ["Average"]
        
        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            
            # å†™å…¥è¡¨å¤´
            writer.writerow(csv_headers)
            
            # æå–æ•°æ®
            transfer_data = metrics["transfer"]["transfer"]
            avg_data = metrics["avg"]["avg"] 
            last_data = metrics["last"]["last"]

            # è®¡ç®—æ¯è¡Œçš„å¹³å‡å€¼
            transfer_avg = np.mean(transfer_data)
            avg_avg = np.mean(avg_data)
            last_avg = np.mean(last_data)
            
            # æ ¼å¼åŒ–å‡½æ•°
            format_acc = lambda x: f"{x:.2f}"

            # å†™å…¥Transferè¡Œ
            transfer_row = ["Transfer", experiment_name] + [format_acc(x) for x in transfer_data] + [format_acc(transfer_avg)]
            writer.writerow(transfer_row)
            
            # å†™å…¥Averageè¡Œ
            avg_row = ["Average", experiment_name] + [format_acc(x) for x in avg_data] + [format_acc(avg_avg)]
            writer.writerow(avg_row)
            
            # å†™å…¥Lastè¡Œ
            last_row = ["Last", experiment_name] + [format_acc(x) for x in last_data] + [format_acc(last_avg)]
            writer.writerow(last_row)
    
    def run_full_evaluation(self, test_script_path: str = "scripts/test_zscl.sh", 
                           experiment_name: str = "ZSCL_Matrix_Evaluation",
                           matrix_csv: str = "accuracy_matrix.csv",
                           metrics_csv: str = "zscl_metrics.csv",
                           checkpoint_dir: str = None):
        """
        è¿è¡Œå®Œæ•´çš„ZSCLçŸ©é˜µè¯„ä¼°
        """
        print(f"ğŸš€ å¼€å§‹ZSCLçŸ©é˜µè¯„ä¼°...")
        print(f"   æµ‹è¯•è„šæœ¬: {test_script_path}")
        print(f"   å®éªŒåç§°: {experiment_name}")
        
        # è¿è¡Œæµ‹è¯•è„šæœ¬å¹¶è·å–çŸ©é˜µ
        matrix = self.run_test_script_and_capture_matrix(test_script_path)
        
        if matrix.sum() == 0:
            print("è­¦å‘Š: æœªæ”¶é›†åˆ°æœ‰æ•ˆçš„å‡†ç¡®ç‡æ•°æ®")
            return

        # å¦‚æœæŒ‡å®šäº†checkpointç›®å½•ï¼Œåˆ™å°†æ–‡ä»¶ä¿å­˜åˆ°è¯¥ç›®å½•
        if checkpoint_dir:
            if not os.path.exists(checkpoint_dir):
                os.makedirs(checkpoint_dir, exist_ok=True)
            matrix_csv = os.path.join(checkpoint_dir, os.path.basename(matrix_csv))
            metrics_csv = os.path.join(checkpoint_dir, os.path.basename(metrics_csv))

        # ä¿å­˜å‡†ç¡®ç‡çŸ©é˜µ
        self.save_accuracy_matrix_csv(matrix, matrix_csv)
        
        # è®¡ç®—å¹¶ä¿å­˜ZSCLæŒ‡æ ‡
        metrics = self.cal_ZSCL_metrics(matrix)
        self.save_zscl_metrics_csv(metrics, experiment_name, metrics_csv)
        
        print(f"\nâœ… è¯„ä¼°ç»“æœå·²ä¿å­˜:")
        print(f"   çŸ©é˜µæ–‡ä»¶: {matrix_csv}")
        print(f"   æŒ‡æ ‡æ–‡ä»¶: {metrics_csv}")
        
        # è¾“å‡ºå…³é”®æŒ‡æ ‡æ‘˜è¦
        print(f"\nğŸ“Š å…³é”®æŒ‡æ ‡æ‘˜è¦:")
        print(f"   ğŸ”„ Transfer Average: {metrics['results_mean']['transfer']:.2f}")
        print(f"   ğŸ“Š Average Performance: {metrics['results_mean']['avg']:.2f}")
        print(f"   ğŸ¯ Last Performance: {metrics['results_mean']['last']:.2f}")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="ZSCLçŸ©é˜µè¯„ä¼°")
    parser.add_argument("--test-script", default="scripts/test_zscl.sh", help="æµ‹è¯•è„šæœ¬è·¯å¾„")
    parser.add_argument("--experiment-name", default="ZSCL_Matrix_Evaluation", help="å®éªŒåç§°")
    parser.add_argument("--matrix-csv", default="accuracy_matrix.csv", help="å‡†ç¡®ç‡çŸ©é˜µè¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--metrics-csv", default="zscl_metrics.csv", help="ZSCLæŒ‡æ ‡è¾“å‡ºæ–‡ä»¶")
    parser.add_argument("--checkpoint-dir", default=None, help="checkpointç›®å½•ï¼Œç»“æœæ–‡ä»¶å°†ä¿å­˜åˆ°æ­¤ç›®å½•")
    parser.add_argument("--model-ckpt-path", default="ckpt/exp_zscl", help="æµ‹è¯•è„šæœ¬ä¸­ä½¿ç”¨çš„æ¨¡å‹checkpointè·¯å¾„")
    
    args = parser.parse_args()
    
    evaluator = ZSCLMatrixEvaluator()
    evaluator.run_full_evaluation(
        args.test_script, 
        args.experiment_name, 
        args.matrix_csv, 
        args.metrics_csv,
        args.checkpoint_dir
    )


if __name__ == "__main__":
    main()